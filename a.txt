训练：构建基础模型。

调优：将模型适配到具体应用场景。

生成、评估与进一步调优：持续提升模型的准确性与适用性。

训练
生成式人工智能始于“基础模型”——这是一种作为多种生成式AI应用核心的深度学习模型。

目前最常见的基础模型是大语言模型（LLMs），主要用于文本生成任务。此外，也存在面向图像、视频、音频或音乐生成的基础模型，以及支持多种内容类型的多模态基础模型。

构建基础模型时，通常在大规模、非结构化、未标注的数据（例如来自互联网的海量文本、图像或视频）上训练深度学习算法。训练过程最终生成一个包含数十亿参数的神经网络，这些参数编码了数据中的模式、结构和关联，使模型能够自主响应用户提示并生成内容，从而形成基础模型。

该训练过程计算密集、耗时且成本高昂，通常需要数千个GPU集群及大量数据处理时间，总投入可达数百万美元。一些开源基础模型项目（如 Meta 的 Llama 2）使生成式AI开发者能够跳过这一步骤，大幅降低开发成本。

调优
接下来，基础模型需针对具体的内容生成任务进行调优。常见的调优方式包括：

微调：使用特定任务的标注数据，包括用户可能提出的问题或提示，以及符合要求的正确答案格式，对模型进行进一步训练。

基于人类反馈的强化学习：人类评估者对模型输出的准确性与相关性进行评判，模型据此自我优化。这一过程类似于用户向聊天机器人或虚拟助手提供反馈或修正指令。

生成、评估与进一步调优
开发人员和用户会定期评估生成式AI应用的输出结果，并持续对模型进行调优，重点在于提升其准确性与相关性。相比之下，基础模型本身的更新频率较低，通常每几个月甚至每年才更新一次。

另一种提升生成式AI应用性能的技术是检索增强生成，该方法在生成过程中引入训练数据之外的相关信息，以增强输出的准确性和上下文相关性。
